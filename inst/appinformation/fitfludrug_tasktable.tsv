"QuizID"	"AppID"	"AppTitle"	"TaskID"	"TaskText"	"RecordID"	"Record"	"Type"	"Note"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	1	"Set the number of uninfected cells to 1e7, 1 virion, and no infected cells at start. Assume that infected cells have an average lifespan of 12 hours and virus of 6 hours. Those parameters are fixed and not fitted. Set virus production rate and infection rate both to 0.002, conversion factor to _g=0_. Set upper and lower bounds for each of these parameters to 0 and 100. For a discussion on parameter bounds, see some of the other fitting apps. The bounds for the treatment strength are hard coded to be 0 and 1. 


Start with the drug turned off (k=0). Run 1 iteration of model 1. I suggest you choose a log scale for the y-axis and plotly as the plot engine. Using plotly allows you to click on the rather busy figure and turn on/off specific model components. You should see all 3 curves (no treatment, early treatment, late treatment) on top of each other and an SSR of around 39. 


Now set drug efficacy to 1, run model 1 for 1 iteration, and then repeat for model 2. You should cleary see the impact of the drug on the virus load curves. You'll find an SSR a bit above 7 for model 1 and a slightly lower SSR and AIC for model 2 (as you learn in another fitting app, if the models have the same number of parameters, which is the case here, SSR and AIC move together and contain the same information, namely lower value means a better fitting model).


Now, fit model 1 for 500 iterations. Be patient, this might take a little while. SSR will have decreased to a bit over 4. Take a look at the numbers below the plot. Those are the estimated values for the parameters at the final iteration of the model (this might or might not be the overall best fit, we'll get back to this). For now, focus on the value for drug efficacy (_f_ for model 1). Remember that for the input, you set drug efficacy with the parameter _k_, which then is mapped to either _f_ or _e_ based on the model. Therefore you will see the best reported for either _f_ or _e_, based on the model you run. You should find it to be 1, i.e. a perfect drug. Next, fit model 2 for 500 iterations. You'll find that it performs slightly better than model 1, and the best fit estimate for the drug efficacy is again 1.


If your computer is fast enough, you can increase to 1000 or more iterations for both models. Results should not change. Based on this, we might conclude that the mechanism of the drug preventing virus production is more likely, given the data and model, and that our estimate for the drug efficacy is that it's a perfect drug. However, as we'll see next, this is not quite a robust result."	"T1R1"	"SSR for model 1, _k_ = 1, 1 iteration"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	1	"Set the number of uninfected cells to 1e7, 1 virion, and no infected cells at start. Assume that infected cells have an average lifespan of 12 hours and virus of 6 hours. Those parameters are fixed and not fitted. Set virus production rate and infection rate both to 0.002, conversion factor to _g=0_. Set upper and lower bounds for each of these parameters to 0 and 100. For a discussion on parameter bounds, see some of the other fitting apps. The bounds for the treatment strength are hard coded to be 0 and 1. 


Start with the drug turned off (k=0). Run 1 iteration of model 1. I suggest you choose a log scale for the y-axis and plotly as the plot engine. Using plotly allows you to click on the rather busy figure and turn on/off specific model components. You should see all 3 curves (no treatment, early treatment, late treatment) on top of each other and an SSR of around 39. 


Now set drug efficacy to 1, run model 1 for 1 iteration, and then repeat for model 2. You should cleary see the impact of the drug on the virus load curves. You'll find an SSR a bit above 7 for model 1 and a slightly lower SSR and AIC for model 2 (as you learn in another fitting app, if the models have the same number of parameters, which is the case here, SSR and AIC move together and contain the same information, namely lower value means a better fitting model).


Now, fit model 1 for 500 iterations. Be patient, this might take a little while. SSR will have decreased to a bit over 4. Take a look at the numbers below the plot. Those are the estimated values for the parameters at the final iteration of the model (this might or might not be the overall best fit, we'll get back to this). For now, focus on the value for drug efficacy (_f_ for model 1). Remember that for the input, you set drug efficacy with the parameter _k_, which then is mapped to either _f_ or _e_ based on the model. Therefore you will see the best reported for either _f_ or _e_, based on the model you run. You should find it to be 1, i.e. a perfect drug. Next, fit model 2 for 500 iterations. You'll find that it performs slightly better than model 1, and the best fit estimate for the drug efficacy is again 1.


If your computer is fast enough, you can increase to 1000 or more iterations for both models. Results should not change. Based on this, we might conclude that the mechanism of the drug preventing virus production is more likely, given the data and model, and that our estimate for the drug efficacy is that it's a perfect drug. However, as we'll see next, this is not quite a robust result."	"T1R2"	"SSR for model 2, _k_ = 1, 1 iteration"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	1	"Set the number of uninfected cells to 1e7, 1 virion, and no infected cells at start. Assume that infected cells have an average lifespan of 12 hours and virus of 6 hours. Those parameters are fixed and not fitted. Set virus production rate and infection rate both to 0.002, conversion factor to _g=0_. Set upper and lower bounds for each of these parameters to 0 and 100. For a discussion on parameter bounds, see some of the other fitting apps. The bounds for the treatment strength are hard coded to be 0 and 1. 


Start with the drug turned off (k=0). Run 1 iteration of model 1. I suggest you choose a log scale for the y-axis and plotly as the plot engine. Using plotly allows you to click on the rather busy figure and turn on/off specific model components. You should see all 3 curves (no treatment, early treatment, late treatment) on top of each other and an SSR of around 39. 


Now set drug efficacy to 1, run model 1 for 1 iteration, and then repeat for model 2. You should cleary see the impact of the drug on the virus load curves. You'll find an SSR a bit above 7 for model 1 and a slightly lower SSR and AIC for model 2 (as you learn in another fitting app, if the models have the same number of parameters, which is the case here, SSR and AIC move together and contain the same information, namely lower value means a better fitting model).


Now, fit model 1 for 500 iterations. Be patient, this might take a little while. SSR will have decreased to a bit over 4. Take a look at the numbers below the plot. Those are the estimated values for the parameters at the final iteration of the model (this might or might not be the overall best fit, we'll get back to this). For now, focus on the value for drug efficacy (_f_ for model 1). Remember that for the input, you set drug efficacy with the parameter _k_, which then is mapped to either _f_ or _e_ based on the model. Therefore you will see the best reported for either _f_ or _e_, based on the model you run. You should find it to be 1, i.e. a perfect drug. Next, fit model 2 for 500 iterations. You'll find that it performs slightly better than model 1, and the best fit estimate for the drug efficacy is again 1.


If your computer is fast enough, you can increase to 1000 or more iterations for both models. Results should not change. Based on this, we might conclude that the mechanism of the drug preventing virus production is more likely, given the data and model, and that our estimate for the drug efficacy is that it's a perfect drug. However, as we'll see next, this is not quite a robust result."	"T1R3"	"SSR for model 1, _k_ = 1, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	1	"Set the number of uninfected cells to 1e7, 1 virion, and no infected cells at start. Assume that infected cells have an average lifespan of 12 hours and virus of 6 hours. Those parameters are fixed and not fitted. Set virus production rate and infection rate both to 0.002, conversion factor to _g=0_. Set upper and lower bounds for each of these parameters to 0 and 100. For a discussion on parameter bounds, see some of the other fitting apps. The bounds for the treatment strength are hard coded to be 0 and 1. 


Start with the drug turned off (k=0). Run 1 iteration of model 1. I suggest you choose a log scale for the y-axis and plotly as the plot engine. Using plotly allows you to click on the rather busy figure and turn on/off specific model components. You should see all 3 curves (no treatment, early treatment, late treatment) on top of each other and an SSR of around 39. 


Now set drug efficacy to 1, run model 1 for 1 iteration, and then repeat for model 2. You should cleary see the impact of the drug on the virus load curves. You'll find an SSR a bit above 7 for model 1 and a slightly lower SSR and AIC for model 2 (as you learn in another fitting app, if the models have the same number of parameters, which is the case here, SSR and AIC move together and contain the same information, namely lower value means a better fitting model).


Now, fit model 1 for 500 iterations. Be patient, this might take a little while. SSR will have decreased to a bit over 4. Take a look at the numbers below the plot. Those are the estimated values for the parameters at the final iteration of the model (this might or might not be the overall best fit, we'll get back to this). For now, focus on the value for drug efficacy (_f_ for model 1). Remember that for the input, you set drug efficacy with the parameter _k_, which then is mapped to either _f_ or _e_ based on the model. Therefore you will see the best reported for either _f_ or _e_, based on the model you run. You should find it to be 1, i.e. a perfect drug. Next, fit model 2 for 500 iterations. You'll find that it performs slightly better than model 1, and the best fit estimate for the drug efficacy is again 1.


If your computer is fast enough, you can increase to 1000 or more iterations for both models. Results should not change. Based on this, we might conclude that the mechanism of the drug preventing virus production is more likely, given the data and model, and that our estimate for the drug efficacy is that it's a perfect drug. However, as we'll see next, this is not quite a robust result."	"T1R4"	"SSR for model 2, _k_ = 1, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	2	"Leave everything as you just had, but now chose the starting value for drug efficacy to be _k=0.5_. Note that this is only a starting value; _k_ is being fit thus, in theory, we should get the same best fit model and best fit estimate for _k_, no matter where we start. Test that by running models 1 and 2 for 500 iterations with this changed starting value of _k_. You'll find that the final iteration for model 1 produces a worse SSR and a different estimate for drug efficacy (compared to starting at _k_ = 1), while model 2 leads to a better fit than before, and also a reduced drug efficacy. If your computer is fast enough, you can again increase the number of iterations. You'll find that the results don't change."	"T2R1"	"SSR for model 1, _k_ = 0.5, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	2	"Leave everything as you just had, but now chose the starting value for drug efficacy to be _k=0.5_. Note that this is only a starting value; _k_ is being fit thus, in theory, we should get the same best fit model and best fit estimate for _k_, no matter where we start. Test that by running models 1 and 2 for 500 iterations with this changed starting value of _k_. You'll find that the final iteration for model 1 produces a worse SSR and a different estimate for drug efficacy (compared to starting at _k_ = 1), while model 2 leads to a better fit than before, and also a reduced drug efficacy. If your computer is fast enough, you can again increase the number of iterations. You'll find that the results don't change."	"T2R2"	"Drug efficacy estimate for model 1"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	2	"Leave everything as you just had, but now chose the starting value for drug efficacy to be _k=0.5_. Note that this is only a starting value; _k_ is being fit thus, in theory, we should get the same best fit model and best fit estimate for _k_, no matter where we start. Test that by running models 1 and 2 for 500 iterations with this changed starting value of _k_. You'll find that the final iteration for model 1 produces a worse SSR and a different estimate for drug efficacy (compared to starting at _k_ = 1), while model 2 leads to a better fit than before, and also a reduced drug efficacy. If your computer is fast enough, you can again increase the number of iterations. You'll find that the results don't change."	"T2R3"	"SSR for model 2, _k_ = 0.5, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	2	"Leave everything as you just had, but now chose the starting value for drug efficacy to be _k=0.5_. Note that this is only a starting value; _k_ is being fit thus, in theory, we should get the same best fit model and best fit estimate for _k_, no matter where we start. Test that by running models 1 and 2 for 500 iterations with this changed starting value of _k_. You'll find that the final iteration for model 1 produces a worse SSR and a different estimate for drug efficacy (compared to starting at _k_ = 1), while model 2 leads to a better fit than before, and also a reduced drug efficacy. If your computer is fast enough, you can again increase the number of iterations. You'll find that the results don't change."	"T2R4"	"Drug efficacy estimate for model 2"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	3	"The finding from the previous task shows another example of the practical difficulty of obtaining the best fit. As discussed in the other apps, for a real research problem, we would need to try different solvers/optimizers, different starting values for the fitted parameters, and fitting to simulated data. This might give us some confidence that we are not overfitting and that our results are robust. If we do that, we might be able to trust our finding, which will tell us which model (and thus mechanism) is more consistent with the data and what the estimate for the drug efficacy is. You can explore this to see what the best fit is you can find for different starting values of the fitted parameters, and different models and iterations. (I found one for model 2 with SSR = 3.0. There might be even better ones for either model.)"	"T3R1"	"Nothing"	"None"	""
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	4	"Note that changing starting values of the fitted parameters as you did in the previous task should, in theory, not change the best fit. If you change values for the fixed parameters, you change your assumptions about the biological problem and, therefore, results are expected to be different. Let's test that briefly. 


Reset inputs to default values. That should produce an average lifespan for infected cells of 24 hours and for virus of 12 hours (twice what we used above). Set drug efficacy to _k = 1_ and run both models 1 and 2 for one iteration. You'll see that the starting values are worse compared to those in the first task. Remember, starting values are not that meaningful, what matters is the final fit result. Run both models 1 and 2 for 500 iterations.


You should find an SSR somewhat above 7 for model 1 and above 4 for model 2. You can try more iterations and different starting values for the fitted parameters to see if you can find better fits. I explored a bit (not exhaustively) and found an SSR of 4.03 for model 2, model 1 always results in a higher value. So, it seems if we change the underlying assumptions of the lifespan of infected cells and virus (which needs to come from external knowledge), model 2 is still better for this specific setup and estimates of drug efficacy are similar. This is not generally the case. If the biological setup changes, model performance can change. All model parameters (and the model structure) need to either be justified based on biological knowledge or through fitting to data. Usually, it is a combination of both."	"T4R1"	"SSR for model 1, _k_ = 1, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
"DSAIRM_fitfludrug"	"fitfludrug"	"Influenza Drug Model"	4	"Note that changing starting values of the fitted parameters as you did in the previous task should, in theory, not change the best fit. If you change values for the fixed parameters, you change your assumptions about the biological problem and, therefore, results are expected to be different. Let's test that briefly. 


Reset inputs to default values. That should produce an average lifespan for infected cells of 24 hours and for virus of 12 hours (twice what we used above). Set drug efficacy to _k = 1_ and run both models 1 and 2 for one iteration. You'll see that the starting values are worse compared to those in the first task. Remember, starting values are not that meaningful, what matters is the final fit result. Run both models 1 and 2 for 500 iterations.


You should find an SSR somewhat above 7 for model 1 and above 4 for model 2. You can try more iterations and different starting values for the fitted parameters to see if you can find better fits. I explored a bit (not exhaustively) and found an SSR of 4.03 for model 2, model 1 always results in a higher value. So, it seems if we change the underlying assumptions of the lifespan of infected cells and virus (which needs to come from external knowledge), model 2 is still better for this specific setup and estimates of drug efficacy are similar. This is not generally the case. If the biological setup changes, model performance can change. All model parameters (and the model structure) need to either be justified based on biological knowledge or through fitting to data. Usually, it is a combination of both."	"T4R2"	"SSR for model 2, _k_ = 1, 500 iterations"	"Rounded_Numeric"	"Round to two significant digits"
